{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "id": "Yx-VOZ1tT-FT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa0ca93-adfd-4f76-aa2b-fb8b4b338bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and Preprocessing of Data\n"
      ],
      "metadata": {
        "id": "fFNEl7FmRHEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "file_path= r'/gdrive/My Drive/CW1_Dataset/resale17dd.xlsx'\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.1, random_state=0)\n",
        "\n",
        "# Normalize the inputs to scale them between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "train_df.iloc[:, :5] = scaler.fit_transform(train_df.iloc[:, :5])\n",
        "test_df.iloc[:, :5] = scaler.transform(test_df.iloc[:, :5])\n"
      ],
      "metadata": {
        "id": "cG9MUK5im1bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining and Training **Multi Layer Perceptron(MLP) Neural Network** - 5x4x10x1"
      ],
      "metadata": {
        "id": "Ja826fuERN5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define MLP Neural Network (5x4x10x1)\n",
        "model_mlp = keras.Sequential([\n",
        "    # Add the first hidden layer with 4 units and ReLU activation\n",
        "    layers.Dense(4, input_shape=(5,), activation='relu'),\n",
        "    # Add the second hidden layer with 10 units and ReLU activation\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    # Add the output layer with 1 unit\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the MLP model with the Adam optimizer and loss funcion mse(mean squared error)\n",
        "model_mlp.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the MLP model\n",
        "history_mlp = model_mlp.fit(train_df.iloc[:, :5], train_df.iloc[:, 5], epochs=2500,batch_size=20, verbose=0)\n",
        "\n",
        "# Evaluate the MLP model on the testing set and training set\n",
        "mlp_test_predictions = model_mlp.predict(test_df.iloc[:, :5])\n",
        "mlp_test_mae = mean_absolute_error(test_df.iloc[:, 5], mlp_test_predictions)\n",
        "mlp_test_mse = mean_squared_error(test_df.iloc[:, 5], mlp_test_predictions)\n",
        "\n",
        "mlp_train_predictions = model_mlp.predict(train_df.iloc[:, :5])\n",
        "mlp_train_mae = mean_absolute_error(train_df.iloc[:, 5],mlp_train_predictions)\n",
        "mlp_train_mse = mean_squared_error(train_df.iloc[:, 5], mlp_train_predictions)\n",
        "\n"
      ],
      "metadata": {
        "id": "u0OoN1nDTqWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd1d760-e85d-4085-a911-c9f56201abb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display MLP Model results"
      ],
      "metadata": {
        "id": "mMNIsV9_EnRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(\"MLP Model -\")\n",
        "print(\"Training MAE: {:.2f}\".format(mlp_train_mae))\n",
        "print(\"Training MSE: {:.2f}\".format(mlp_train_mse))\n",
        "print(\"Testing MAE: {:.2f}\".format(mlp_test_mae))\n",
        "print(\"Testing MSE: {:.2f}\".format(mlp_test_mse))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MUgNO3qEijo",
        "outputId": "640cdfe3-ef64-4adc-a04f-9ff35d8060c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Model -\n",
            "Training MAE: 66059.89\n",
            "Training MSE: 8267771725.51\n",
            "Testing MAE: 67175.16\n",
            "Testing MSE: 8309705658.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining and Training Deep Convolutional Neural Network(CNN) Model\n",
        "\n"
      ],
      "metadata": {
        "id": "VJ2EMeU5nQip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Deep Convolutional Neural Network(CNN) Model\n",
        "model_cnn = keras.Sequential([\n",
        "    # Add the first convolutional layer with 32 filters and ReLU activation\n",
        "    layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(5, 1)),\n",
        "    # Add the second convolutional layer with 64 filters and ReLU activation\n",
        "    layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
        "    # Add a flatten layer\n",
        "    layers.Flatten(),\n",
        "    # Add a dense layer\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    # Add a batch normalization layer\n",
        "    layers.BatchNormalization(),\n",
        "    # Add a dropout layer with a rate of 0.75\n",
        "    layers.Dropout(0.75),\n",
        "    # Add a dense output layer with unit 1\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the CNN model with the Adam optimizer and loss funcion mse(mean squared error)\n",
        "model_cnn.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the CNN model\n",
        "history_cnn = model_cnn.fit(train_df.iloc[:, :5], train_df.iloc[:, 5], epochs=800, batch_size=20, verbose=0)\n",
        "\n",
        "\n",
        "# Evaluate the CNN model on the testing set and training set\n",
        "cnn_test_predictions = model_cnn.predict(test_df.iloc[:, :5])\n",
        "cnn_test_mae = mean_absolute_error(test_df.iloc[:, 5], cnn_test_predictions)\n",
        "cnn_test_mse = mean_squared_error(test_df.iloc[:, 5], cnn_test_predictions)\n",
        "\n",
        "cnn_train_predictions = model_cnn.predict(train_df.iloc[:, :5])\n",
        "cnn_train_mae = mean_absolute_error(train_df.iloc[:, 5],cnn_train_predictions)\n",
        "cnn_train_mse = mean_squared_error(train_df.iloc[:, 5], cnn_train_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOMVBlDHD_Ij",
        "outputId": "6abb227c-5750-4ecb-f87a-5cab22855b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Deep Convolutional NN Results"
      ],
      "metadata": {
        "id": "ZBlwksSIE-8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(\"Deep Convolutional NN Model\")\n",
        "print(\"Training MAE: {:.2f}\".format(cnn_train_mae))\n",
        "print(\"Training MSE: {:.2f}\".format(cnn_train_mse))\n",
        "print(\"Testing MAE: {:.2f}\".format(cnn_test_mae))\n",
        "print(\"Testing MSE: {:.2f}\".format(cnn_test_mse))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VO_x7o1E6ti",
        "outputId": "f5eedfd5-d9f2-40f2-c948-e69d20cac423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Convolutional NN Model\n",
            "Training MAE: 51361.54\n",
            "Training MSE: 5308377170.67\n",
            "Testing MAE: 52111.09\n",
            "Testing MSE: 5456069368.35\n"
          ]
        }
      ]
    }
  ]
}